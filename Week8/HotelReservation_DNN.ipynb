{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c606add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f2bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\simra\\\\Downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45d7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"hotel_res_train_X.csv\")\n",
    "X_test = pd.read_csv(\"hotel_res_test_X.csv\")\n",
    "y_train = pd.read_csv(\"hotel_res_train_y.csv\")\n",
    "y_test = pd.read_csv(\"hotel_res_test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1a9eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>...</th>\n",
       "      <th>reserved_Room_Type 3</th>\n",
       "      <th>reserved_Room_Type 4</th>\n",
       "      <th>reserved_Room_Type 5</th>\n",
       "      <th>reserved_Room_Type 6</th>\n",
       "      <th>reserved_Room_Type 7</th>\n",
       "      <th>market_segment_type_Aviation</th>\n",
       "      <th>market_segment_type_Complementary</th>\n",
       "      <th>market_segment_type_Corporate</th>\n",
       "      <th>market_segment_type_Offline</th>\n",
       "      <th>market_segment_type_Online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.629881</td>\n",
       "      <td>-0.262925</td>\n",
       "      <td>0.216149</td>\n",
       "      <td>-0.143648</td>\n",
       "      <td>-0.181176</td>\n",
       "      <td>-0.619528</td>\n",
       "      <td>0.46661</td>\n",
       "      <td>-1.759539</td>\n",
       "      <td>-1.210875</td>\n",
       "      <td>-0.163232</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.629881</td>\n",
       "      <td>-0.262925</td>\n",
       "      <td>0.216149</td>\n",
       "      <td>-0.143648</td>\n",
       "      <td>-0.181176</td>\n",
       "      <td>-0.818817</td>\n",
       "      <td>0.46661</td>\n",
       "      <td>-0.133387</td>\n",
       "      <td>-0.868052</td>\n",
       "      <td>-0.163232</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.294062</td>\n",
       "      <td>-0.262925</td>\n",
       "      <td>1.365321</td>\n",
       "      <td>-1.566784</td>\n",
       "      <td>-0.181176</td>\n",
       "      <td>-0.783649</td>\n",
       "      <td>0.46661</td>\n",
       "      <td>-0.458617</td>\n",
       "      <td>1.188886</td>\n",
       "      <td>-0.163232</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.294062</td>\n",
       "      <td>-0.262925</td>\n",
       "      <td>-0.933023</td>\n",
       "      <td>1.279489</td>\n",
       "      <td>-0.181176</td>\n",
       "      <td>2.475321</td>\n",
       "      <td>0.46661</td>\n",
       "      <td>0.517075</td>\n",
       "      <td>0.617514</td>\n",
       "      <td>-0.163232</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.629881</td>\n",
       "      <td>-0.262925</td>\n",
       "      <td>-0.933023</td>\n",
       "      <td>-0.143648</td>\n",
       "      <td>-0.181176</td>\n",
       "      <td>1.209247</td>\n",
       "      <td>0.46661</td>\n",
       "      <td>-0.458617</td>\n",
       "      <td>-0.068132</td>\n",
       "      <td>-0.163232</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "0     -1.629881       -0.262925              0.216149          -0.143648   \n",
       "1     -1.629881       -0.262925              0.216149          -0.143648   \n",
       "2      0.294062       -0.262925              1.365321          -1.566784   \n",
       "3      0.294062       -0.262925             -0.933023           1.279489   \n",
       "4     -1.629881       -0.262925             -0.933023          -0.143648   \n",
       "\n",
       "   required_car_parking_space  lead_time  arrival_year  arrival_month  \\\n",
       "0                   -0.181176  -0.619528       0.46661      -1.759539   \n",
       "1                   -0.181176  -0.818817       0.46661      -0.133387   \n",
       "2                   -0.181176  -0.783649       0.46661      -0.458617   \n",
       "3                   -0.181176   2.475321       0.46661       0.517075   \n",
       "4                   -0.181176   1.209247       0.46661      -0.458617   \n",
       "\n",
       "   arrival_date  repeated_guest  ...  reserved_Room_Type 3  \\\n",
       "0     -1.210875       -0.163232  ...                     0   \n",
       "1     -0.868052       -0.163232  ...                     0   \n",
       "2      1.188886       -0.163232  ...                     0   \n",
       "3      0.617514       -0.163232  ...                     0   \n",
       "4     -0.068132       -0.163232  ...                     0   \n",
       "\n",
       "   reserved_Room_Type 4  reserved_Room_Type 5  reserved_Room_Type 6  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   reserved_Room_Type 7  market_segment_type_Aviation  \\\n",
       "0                     0                             0   \n",
       "1                     0                             0   \n",
       "2                     0                             0   \n",
       "3                     0                             0   \n",
       "4                     0                             0   \n",
       "\n",
       "   market_segment_type_Complementary  market_segment_type_Corporate  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "\n",
       "   market_segment_type_Offline  market_segment_type_Online  \n",
       "0                            0                           1  \n",
       "1                            0                           1  \n",
       "2                            0                           1  \n",
       "3                            1                           0  \n",
       "4                            1                           0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf22e6a0",
   "metadata": {},
   "source": [
    "### Modeling data\n",
    "First, let's create a dataframe to load the model performance metrics into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d357abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097a3be",
   "metadata": {},
   "source": [
    "### Evaluation metric\n",
    "In our dataset, for end goal, we are predicting the column 'booking_status_Not_Canceled' which is 1 when the reservation remains intact, and 0 when it is called-off. The selection of metric would depend on what parameter leads to maximum loss reduction to the business.\n",
    "Interpretation for the confusion matrix:\n",
    "\n",
    "TP= not canceled detected 1 correctly means the booking remained.\n",
    "\n",
    "TN= not canceled detected 0 correctly means the booking got cancelled.\n",
    "\n",
    "FP= not canceled detected 1 wrongly means detected that booking is there but it is actually cancelled.\n",
    "\n",
    "FN= not canceled detected 0 wrongly means detected that booking is cancelled but instead it is actually intact.\n",
    "\n",
    "Therefore FN and FP both need to be reduced because increase in both the cases would lead to loss in different ways.\n",
    "Increased FP will lead to underutilization of rooms therefore revenue loss as there will be empty rooms available. \n",
    "Increased FN will lead to overbooking and therefore when customers arrive, it would lead to their dissatisfaction with the service as someone will have to adjust or compromize on either another room or another hotel. This would indirectly impact the ratings of the hotel and lead to loss in revenue. \n",
    "\n",
    "Precision metric takes care of the FP and Recall metric takes care of the FN, but we are interested to reduce both FP and FN.\n",
    "Hence, for modeling data, we will use F1-score as it takes care of both metrics by taking their harmonic mean. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9eb02e",
   "metadata": {},
   "source": [
    "#### Logistic Regression Random Search CV using default, L1, L2, Elastic, liblinear regularization\n",
    "Conduct an initial random search across a wide range of possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d989a396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The best f1 score is 0.7794295844412918\n",
      "... with parameters: {'solver': 'saga', 'penalty': 'l1', 'max_iter': 109}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter':np.arange(90,110),\n",
    "    'penalty': ['None','l1','l2','elasticnet'],\n",
    "    'solver':['saga','liblinear']\n",
    "}\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = log_reg, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c97b78c",
   "metadata": {},
   "source": [
    "#### Logistic Regression Grid Search CV using default, L1, L2, Elastic, liblinear regularization\n",
    "Conduct an exhaustive search across a smaller range of parameters around the parameters found in the initial random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64d9a9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "The best f1 score is 0.7794295844412918\n",
      "... with parameters: {'max_iter': 104, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "max_iter = rand_search.best_params_['max_iter']\n",
    "penalty = rand_search.best_params_['penalty']\n",
    "solver = rand_search.best_params_['solver']\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter': np.arange(max_iter-5,max_iter+5),  \n",
    "    'penalty': [penalty],\n",
    "    'solver': [solver]\n",
    "}\n",
    "\n",
    "log_reg_model = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = log_reg_model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestf1_logistic = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d0621bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.785721</td>\n",
       "      <td>0.879089</td>\n",
       "      <td>0.792148</td>\n",
       "      <td>0.833357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.785721   0.879089  0.792148  0.833357"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Regression\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41550f7d",
   "metadata": {},
   "source": [
    "#### SVM Random Search CV using linear, rbf and poly kernal\n",
    "Conduct an initial random search across a wide range of possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "926447b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "The best f1 score is 0.8191377481759609\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 'scale', 'C': 5}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(1,15),   \n",
    "    'gamma': ['scale','auto'],\n",
    "    'kernel':['linear','rbf','poly']\n",
    "}\n",
    "\n",
    "svm_m1 = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = svm_m1, param_distributions=param_grid, cv=kfolds, n_iter=2,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aae774",
   "metadata": {},
   "source": [
    "#### SVM Grid Search CV using linear, rbf and poly kernal\n",
    "Conduct an initial random search across a wide range of possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ff72a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "The best f1 score is 0.8195533072379352\n",
      "... with parameters: {'C': 4, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "\n",
    "C = rand_search.best_params_['C']\n",
    "gamma = rand_search.best_params_['gamma']\n",
    "kernel = rand_search.best_params_['kernel']\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(C-1,C+1),  \n",
    "    'gamma': [gamma],\n",
    "    'kernel': [kernel]\n",
    "    \n",
    "}\n",
    "\n",
    "svm_model = SVC()\n",
    "grid_search = GridSearchCV(estimator = svm_model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestf1_SVM = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ea908b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.785721</td>\n",
       "      <td>0.879089</td>\n",
       "      <td>0.792148</td>\n",
       "      <td>0.833357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.823211</td>\n",
       "      <td>0.910836</td>\n",
       "      <td>0.818775</td>\n",
       "      <td>0.862355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.785721   0.879089  0.792148  0.833357\n",
       "0                  SVM  0.823211   0.910836  0.818775  0.862355"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ef1e2e",
   "metadata": {},
   "source": [
    "#### DTree Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4ae82ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "The best f1 score is 0.826500027995135\n",
      "... with parameters: {'min_samples_split': 22, 'min_samples_leaf': 35, 'min_impurity_decrease': 0.0006000000000000001, 'max_leaf_nodes': 58, 'max_depth': 14, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,100),  \n",
    "    'min_samples_leaf': np.arange(1,100),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(5,15), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=50,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e850bb8",
   "metadata": {},
   "source": [
    "#### DTree Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "879002cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1280 candidates, totalling 3840 fits\n",
      "The best f1 score is 0.8283334369927218\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 12, 'max_leaf_nodes': 59, 'min_impurity_decrease': 0.0005, 'min_samples_leaf': 33, 'min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"f1\"\n",
    "kfolds = 3\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestf1_dtree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74f5c7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.785721</td>\n",
       "      <td>0.879089</td>\n",
       "      <td>0.792148</td>\n",
       "      <td>0.833357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.823211</td>\n",
       "      <td>0.910836</td>\n",
       "      <td>0.818775</td>\n",
       "      <td>0.862355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.842047</td>\n",
       "      <td>0.896542</td>\n",
       "      <td>0.866458</td>\n",
       "      <td>0.881244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.785721   0.879089  0.792148  0.833357\n",
       "0                  SVM  0.823211   0.910836  0.818775  0.862355\n",
       "0        Decision Tree  0.842047   0.896542  0.866458  0.881244"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13663a08",
   "metadata": {},
   "source": [
    "#### Best Estimators for the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f77d6319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(max_iter=105, penalty='l1', solver='saga'),\n",
       " SVC(C=8),\n",
       " DecisionTreeClassifier(criterion='entropy', max_depth=11, max_leaf_nodes=77,\n",
       "                        min_impurity_decrease=0.0005, min_samples_leaf=25,\n",
       "                        min_samples_split=22)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best= [bestf1_logistic,bestf1_SVM,bestf1_dtree]\n",
    "best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900295f0",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Arranged by f1 score, the best models are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cba62a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.842047</td>\n",
       "      <td>0.896542</td>\n",
       "      <td>0.866458</td>\n",
       "      <td>0.881244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.823211</td>\n",
       "      <td>0.910836</td>\n",
       "      <td>0.818775</td>\n",
       "      <td>0.862355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.785721</td>\n",
       "      <td>0.879089</td>\n",
       "      <td>0.792148</td>\n",
       "      <td>0.833357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0        Decision Tree  0.842047   0.896542  0.866458  0.881244\n",
       "0                  SVM  0.823211   0.910836  0.818775  0.862355\n",
       "0  Logistic Regression  0.785721   0.879089  0.792148  0.833357"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['F1'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c961e",
   "metadata": {},
   "source": [
    "Due to technical limitations, models with few iterations were run which gave the above described F1-score. It seems that for our model the best performing model out of the three is SVM Classifier. \n",
    "\n",
    "Predicting correct booking cancellations would help the business in two ways-\n",
    "\n",
    "-->There would be no empty rooms i.e. underutilization of the property.\n",
    "\n",
    "-->There would be no customer issues who could clash on not getting the rooms because of overbooking, which eventually will lead to good reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0eb42",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e39f8c",
   "metadata": {},
   "source": [
    "#### With Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecee0e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "{'solver': 'sgd', 'max_iter': 100, 'learning_rate_init': 0.2, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (70,), 'alpha': 0.2, 'activation': 'relu'}\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (70,),(50,30), (40,20)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [100]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=50,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestf1Tree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccc0d772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.77      3522\n",
      "           1       0.92      0.83      0.87      7361\n",
      "\n",
      "    accuracy                           0.83     10883\n",
      "   macro avg       0.81      0.84      0.82     10883\n",
      "weighted avg       0.85      0.83      0.84     10883\n",
      "\n",
      "Wall time: 32.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestf1Tree.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fcc76c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'activation': 'relu', 'alpha': 0.5, 'hidden_layer_sizes': (70,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'adam'}\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [100]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestf1Tree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfbd6736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.74      3522\n",
      "           1       0.90      0.81      0.85      7361\n",
      "\n",
      "    accuracy                           0.81     10883\n",
      "   macro avg       0.79      0.81      0.80     10883\n",
      "weighted avg       0.83      0.81      0.82     10883\n",
      "\n",
      "Wall time: 26.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestf1Tree.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6faa9e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.785721</td>\n",
       "      <td>0.879089</td>\n",
       "      <td>0.792148</td>\n",
       "      <td>0.833357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.823211</td>\n",
       "      <td>0.910836</td>\n",
       "      <td>0.818775</td>\n",
       "      <td>0.862355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.842047</td>\n",
       "      <td>0.896542</td>\n",
       "      <td>0.866458</td>\n",
       "      <td>0.881244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.811817</td>\n",
       "      <td>0.901830</td>\n",
       "      <td>0.809944</td>\n",
       "      <td>0.853421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.785721   0.879089  0.792148  0.833357\n",
       "0                  SVM  0.823211   0.910836  0.818775  0.862355\n",
       "0        Decision Tree  0.842047   0.896542  0.866458  0.881244\n",
       "0                  ANN  0.811817   0.901830  0.809944  0.853421"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"ANN\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "245b1337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.842047</td>\n",
       "      <td>0.896542</td>\n",
       "      <td>0.866458</td>\n",
       "      <td>0.881244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.823211</td>\n",
       "      <td>0.910836</td>\n",
       "      <td>0.818775</td>\n",
       "      <td>0.862355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.811817</td>\n",
       "      <td>0.901830</td>\n",
       "      <td>0.809944</td>\n",
       "      <td>0.853421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.785721</td>\n",
       "      <td>0.879089</td>\n",
       "      <td>0.792148</td>\n",
       "      <td>0.833357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0        Decision Tree  0.842047   0.896542  0.866458  0.881244\n",
       "0                  SVM  0.823211   0.910836  0.818775  0.862355\n",
       "0                  ANN  0.811817   0.901830  0.809944  0.853421\n",
       "0  Logistic Regression  0.785721   0.879089  0.792148  0.833357"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['F1'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba231efa",
   "metadata": {},
   "source": [
    "For this dataset, ANN doesn't seem to be the best model considering the parameters selected. It might turn better if we tune the model or use a larger dataset maybe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fff00a",
   "metadata": {},
   "source": [
    "## Keras with sklearn search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d0d1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3b3e0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_nn = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5ecd7984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.72 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_clf(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    target_encoder_ = meta[\"target_encoder_\"]\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=n_features_in_)),\n",
    "    #for hidden_layer_size in hidden_layer_sizes:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, \n",
    "            kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "            bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "            activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #though you could return a compiled model, it's not necessary, and would result in the loss of these\n",
    "    # parameters in the tune process - as they would be 'hard coded'\n",
    "    # model.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f67e4e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 21.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 20,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=20,\n",
    "    dropout=0.5,\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    optimizer__learning_rate=0.0001\n",
    ")\n",
    "keras_clf.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa9b4db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 20,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    \n",
    "    # the following are model parameters, and therefore must be defined as parameters in the KarasClassifier, and then in the build_clf function\n",
    "    'model__hidden_layer_sizes': [(20,),(30, ), (35,), (40, 30)], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    'model__dropout': [0, 0.1], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    \n",
    "    # the following are 'fit' parameters, the scikeras wrapper provides these parameters. These are passed to the 'model.fit' method for each fit of the model\n",
    "    'batch_size':[200, 600, 500],\n",
    "    'epochs':[5],\n",
    "    'optimizer':['adam','sgd'],\n",
    "    'loss':['binary_crossentropy'],\n",
    "    \n",
    "    # this is added to the optimizer \n",
    "    'optimizer__learning_rate': [0.0001, 0.001, 0.01]\n",
    "\n",
    "}\n",
    "keras_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07ed32b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 4ms/step - loss: 0.7143\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7119\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7106\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7118\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7095\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 3ms/step - loss: 0.7229\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7204\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7200\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7205\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7192\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 3ms/step - loss: 0.7597\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7562\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7529\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7509\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7484\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 4ms/step - loss: 0.6852\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6092\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5535\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5129\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4888\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 5ms/step - loss: 0.6500\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5760\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5014\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4914\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 4ms/step - loss: 0.6467\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5720\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5238\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4995\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4812\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 3ms/step - loss: 0.6865\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6764\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6691\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6618\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6549\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 3ms/step - loss: 0.7885\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7756\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7619\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7522\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7418\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 3ms/step - loss: 0.6879\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6812\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6721\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6653\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6580\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 0.7393\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7311\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7234\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7162\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7094\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 0.6852\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6794\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6738\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6684\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6631\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 0.7267\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7195\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7127\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7061\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.6997\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 0.7214\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6936\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6700\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6501\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6329\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 0.7434\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7155\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6952\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.6794\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6667\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 0.7552\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.7279\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.7050\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6858\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6693\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "28/28 [==============================] - 1s 3ms/step - loss: 0.6602\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5818\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5189\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4857\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4739\n",
      "CPU times: total: 49.7 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(\n",
    "    estimator=keras_clf, \n",
    "    param_distributions=params, \n",
    "    scoring='f1',  # we could use any appropriate sklearn metric here (i.e. accuracy, f1_micro, f1_macro)\n",
    "    n_iter=5, \n",
    "    cv=3)\n",
    "\n",
    "# In rare cases, you may find your model training results in exceeding python's default recursion limit.\n",
    "# If needed, you can increase this excersion limit by using the following code.\n",
    "#import sys\n",
    "#sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e42f8138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.001,\n",
       " 'optimizer': 'adam',\n",
       " 'model__hidden_layer_sizes': (40, 30),\n",
       " 'model__dropout': 0.1,\n",
       " 'loss': 'binary_crossentropy',\n",
       " 'epochs': 5,\n",
       " 'batch_size': 600}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7d839fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "130d8d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "19/19 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, best_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "376ae7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keras with sklearn search</td>\n",
       "      <td>0.790131</td>\n",
       "      <td>0.879134</td>\n",
       "      <td>0.7946</td>\n",
       "      <td>0.834732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Accuracy  Precision  Recall        F1\n",
       "0  Keras with sklearn search  0.790131   0.879134  0.7946  0.834732"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TP = cm[1][1]\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "performance_nn = pd.concat([performance_nn, pd.DataFrame({'model':\"Keras with sklearn search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac058331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6550    0.7812    0.7126      3624\n",
      "           1     0.8791    0.7946    0.8347      7259\n",
      "\n",
      "    accuracy                         0.7901     10883\n",
      "   macro avg     0.7671    0.7879    0.7736     10883\n",
      "weighted avg     0.8045    0.7901    0.7940     10883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, best_model.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ba4f5",
   "metadata": {},
   "source": [
    "The best model that reduces the loss function has 'model__hidden_layer_sizes': (40, 30) and 'batch_size': 600 for 5 epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6b74e",
   "metadata": {},
   "source": [
    "## Keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7d3fc0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "52fc9a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "# If you don't have keras_tuner installed, run the following in your terminal (mac), or anaconda prompt (windows)\n",
    "# conda install -c conda-forge keras-tuner\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f2cb31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true = K.ones_like(y_true)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall_keras = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall_keras\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true = K.ones_like(y_true)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision_keras = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision_keras\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    y_true = K.ones_like(y_true)\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    return tn / (tn + fp + K.epsilon())\n",
    "\n",
    "\n",
    "def negative_predictive_value(y_true, y_pred):\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "    return tn / (tn + fn + K.epsilon())\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    num = (1 + beta ** 2) * (p * r)\n",
    "    den = (beta ** 2 * p + r + K.epsilon())\n",
    "    return K.mean(num / den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "acd0b309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1d0043c3550>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # create input layer\n",
    "    model.add(layers.Input(30))\n",
    "\n",
    "    dropout = hp.Boolean(\"dropout\") # generate a boolean variable called dropout whos value is randomly set to either True of False\n",
    "    normalize = hp.Boolean(\"normalize\") # generate a boolean variable called normalize whos value is randomly set to either True of False\n",
    "\n",
    "    # create hidden layers\n",
    "    for i in range(hp.Int(name='hidden_layer_count', min_value=1, max_value=5, step=1)):\n",
    "        model.add(layers.Dense(units=hp.Int(\"units\", min_value=32, max_value=1024, step=32),activation=hp.Choice(\"activation\", [\"selu\", \"elu\", \"relu\", \"tanh\"]))) \n",
    "        if dropout:\n",
    "            model.add(layers.Dropout(rate=hp.Float(\"dropout rate\", min_value=0.01, max_value=0.1, step=.005)))\n",
    "        if normalize:\n",
    "            model.add(layers.Normalization())\n",
    "\n",
    "    model.add(layers.Dense(units=2, activation=\"softmax\"))\n",
    "\n",
    "    # Define the optimizer learning rate as a hyperparameter.\n",
    "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")   \n",
    "    choice = hp.Choice(name='optimizer', values=['adam', 'sgd'])\n",
    "    if 'adam' == choice:\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=lr)  # for M1/M2 use optimizers.legacy.Adam, otherwise use optimizers.Adam\n",
    "    else:\n",
    "        optimizer = keras.optimizers.legacy.SGD(learning_rate=lr)  # for M1/M2 use optimizers.legacy.SGD, otherwise use optimizers.SGD\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        # see here https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "        \n",
    "        # Though you can add a metric, this doesn't get used to train the model, it's only informative (see previous notebook for more detail).\n",
    "        metrics=[f1],  # you need to set this in order for keras_tuner to have one of these objectives!\n",
    "        # for metrics, see https://www.tensorflow.org/api_docs/python/tf/keras/metrics/\n",
    "    )\n",
    "    return model\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7f2de4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "datestring = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ce9868d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=keras_tuner.Objective(\"val_f1\", direction=\"max\"),\n",
    "# \n",
    "# You can use metrics other than accuracy, but you need to have this defined in the build model first\n",
    "# For instance, if you have f1 defined in the build model, to have keras_tuner 'tune' on f1, you set objective to be 'val_f1'. \n",
    "# For precision you would have to have precision defined in the build model, and to tune on precision, you set the object to \n",
    "# be 'val_precision', etc.\n",
    "# \n",
    "# Also, for custom objectives, you need to set a 'direction' for the tune... so if you want to maximize f1, you set direction to be 'max'.\n",
    "# \n",
    "#    objective = keras_tuner.Objective(\"val_f1\", direction=\"max\"), \n",
    "  \n",
    "    max_trials=10, # max_trials represents the number of hyperparameter combinations that will be tested by the tuner (like n_iter in sklearn random search)\n",
    "    executions_per_trial=2, # max number of models to fit per set of set of hyperparameters combinations\n",
    "\n",
    "    # the next three parameters about where the results from the training are stored\n",
    "    directory=f'logs/{datestring:s}',\n",
    "    project_name=\"keras_tuned\",\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "243eaa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 39s]\n",
      "val_f1: 1.0\n",
      "\n",
      "Best val_f1 So Far: 1.0\n",
      "Total elapsed time: 00h 05m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "CPU times: total: 28min 39s\n",
      "Wall time: 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "    \n",
    "epoch_callback = LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch,logs: print(f'Starting Epoch {epoch+1}!')\n",
    ")\n",
    "\n",
    "batch_loss_callback = LambdaCallback(\n",
    "    on_batch_end=lambda batch,logs: print(f'\\n After batch {batch}, the loss is {logs}.')\n",
    ")\n",
    "    \n",
    "train_finish_callback = LambdaCallback(\n",
    "    on_train_end=lambda logs: print('Training finished!')\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=5, \n",
    "    batch_size=500, \n",
    "    validation_data=(X_test, y_test), \n",
    "    callbacks=[epoch_callback, batch_loss_callback, train_finish_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7c6d1ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': False,\n",
       " 'normalize': True,\n",
       " 'hidden_layer_count': 2,\n",
       " 'units': 896,\n",
       " 'activation': 'selu',\n",
       " 'lr': 0.004041246752831233,\n",
       " 'optimizer': 'sgd'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "best_hps[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "800ee402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 896)               27776     \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 896)              1793      \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 896)               803712    \n",
      "                                                                 \n",
      " normalization_1 (Normalizat  (None, 896)              1793      \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 1794      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 836,868\n",
      "Trainable params: 833,282\n",
      "Non-trainable params: 3,586\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get list of the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "# select the first one in the list (this is the best performing model)\n",
    "best_model = models[0] # select the first one\n",
    "# display summary of model training\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0c1c10f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/341 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2791,  833],\n",
       "       [1846, 5413]], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the confusion matrix\n",
    "cm = confusion_matrix(y_test, best_model.predict(X_test).argmax(axis=1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bbe30ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keras with sklearn search</td>\n",
       "      <td>0.790131</td>\n",
       "      <td>0.879134</td>\n",
       "      <td>0.794600</td>\n",
       "      <td>0.834732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keras tuner</td>\n",
       "      <td>0.753836</td>\n",
       "      <td>0.866635</td>\n",
       "      <td>0.745695</td>\n",
       "      <td>0.801629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Accuracy  Precision    Recall        F1\n",
       "0  Keras with sklearn search  0.790131   0.879134  0.794600  0.834732\n",
       "0                Keras tuner  0.753836   0.866635  0.745695  0.801629"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = cm[1][1]\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "performance_nn = pd.concat([performance_nn, pd.DataFrame({'model':\"Keras tuner\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aab4cfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/341 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6019    0.7701    0.6757      3624\n",
      "           1     0.8666    0.7457    0.8016      7259\n",
      "\n",
      "    accuracy                         0.7538     10883\n",
      "   macro avg     0.7343    0.7579    0.7387     10883\n",
      "weighted avg     0.7785    0.7538    0.7597     10883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,best_model.predict(X_test).argmax(axis=1), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98b69d",
   "metadata": {},
   "source": [
    "The keras search with keras tuner doesn't seem to be improving on f1 alot. This might be due to small range of tested parameters which were selected because of time and processing limitations. Although, keras layers with sklearn search seem be be equivalent to SVM while considering f1. Also, wanted to mention that the keras model wasn't predicting the 1's in the binary classification therefore tried it as a multiclass variable with 2 classes 0 and 1. Without considering, metrics were not being calculated as they were 0's and NA's due to 0 predictions of category 1. Hence, used softmax for the output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764005f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
